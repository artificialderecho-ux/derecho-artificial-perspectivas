---
title: "Carta ética europea sobre el uso de la inteligencia artificial en los sistemas judiciales y su entorno"
author: "Ricardo Scarpa (derechoartificial.com)"
date: "2026-02-16"
category: "Ética IA"
pdf: "/main/public/fuentes/carta_europea_inteligencia artificial.pdf"
tags: ["Artificial Intelligence", "Judicial Systems", "Fundamental Rights", "Non-discrimination", "Quality and Security", "Transparency", "User Control", "Predictive Justice", "Machine Learning", "Data Protection"]
description: "Revisión Bibliográfica"
---

# Carta ética europea sobre el uso de la inteligencia artificial en los sistemas judiciales y su entorno

## 1. Introducción al Marco Ético de la IA en la Justicia

La transformación digital en los Estados miembros del Consejo de Europa no constituye un mero avance administrativo, sino una **reconfiguración estratégica** que exige equilibrar la eficiencia tecnológica con la salvaguarda innegociable de los derechos fundamentales.

Según las directrices de la **Comisión Europea para la Eficiencia de la Justicia (CEPEJ)**, este despliegue debe estar anclado en el bloque de convencionalidad constituido por el **Convenio Europeo de Derechos Humanos (CEDH)** y el **Convenio 108**.

La integración de la **Inteligencia Artificial (IA)** en la infraestructura judicial promete optimizar la celeridad procesal, pero enfrenta riesgos ónticos que amenazan la independencia del juzgador y la equidad del proceso.

La **Carta Ética Europea sobre el uso de la IA en los sistemas judiciales** actúa como un marco regulatorio preventivo diseñado para orientar el diseño y despliegue de herramientas de ciencia de datos en el sector público. Su propósito es transitar desde una regulación reactiva hacia un paradigma de *ethical-by-design* y *human-rights-by-design*.

Los **cinco principios fundamentales** de la Carta son:

- **Respeto a los derechos fundamentales**  
  Garantizar el acceso al juez y el derecho a un juicio justo, compatible con el CEDH desde la concepción del algoritmo.

- **No discriminación**  
  Prevenir activamente que los algoritmos procesen datos sensibles (origen étnico, creencias, orientación sexual) de modo discriminatorio.

- **Calidad y seguridad**  
  Uso de fuentes certificadas, datos íntegros y entornos tecnológicos seguros con diseño multidisciplinar.

- **Transparencia, imparcialidad y equidad**  
  Métodos de procesamiento inteligibles y auditables externamente, equilibrando propiedad intelectual e interés de la justicia.

- **Bajo control del usuario**  
  El juez mantiene autonomía total, control sobre las opciones y capacidad de apartarse de cualquier sugerencia algorítmica.

## 2. Paradigma Técnico: Aprendizaje Automático vs. Razonamiento Jurídico

Es clave desmitificar el discurso de la “justicia predictiva”. No se trata de clarividencia, sino de *forecasting* estadístico basado en datos históricos.

El **aprendizaje automático** (*machine learning*) **no replica** el razonamiento jurídico humano (teleológico y axiológico). Opera inductivamente: vincula grupos léxicos con resultados estadísticos sin comprender el significado normativo.

| Característica              | Sistema Experto Tradicional                          | Aprendizaje Automático (Machine Learning)                     |
|-----------------------------|------------------------------------------------------|---------------------------------------------------------------|
| **Base operativa**          | Reglas lógicas y silogismos predefinidos por humanos | Identificación de patrones estadísticos por la máquina       |
| **Proceso**                 | Deductivo: norma → hecho                              | Inductivo: patrones desde Big Data                            |
| **Limitaciones**            | Ineficaz ante textura abierta del derecho            | IA Débil; no distingue causalidad de correlación              |
| **Riesgo Ontológico**       | Rigidez interpretativa                               | Correlaciones falsas (Teoría de Ramsey), determinismo histórico |

## 3. La Infraestructura de Datos: Open Data y Privacidad

Los datos judiciales son el “petróleo del siglo XXI”. La política de **open data** es requisito para entrenar modelos de IA, pero plantea serios desafíos:

- Anonimización real vs. seudonimización (casi imposible en Big Data por re-identificación)
- **Riesgos concretos**:
  1. Perfilado de jueces (*judge profiling*)
  2. Búsqueda estratégica de foro (*forum shopping*)
  3. Vulneración del **Art. 22 GDPR** (decisiones automatizadas sin supervisión humana)

Una base de datos sesgada cristaliza injusticias históricas bajo apariencia de neutralidad técnica.

## 4. Aplicaciones Sectoriales: Justicia Civil, Comercial y Administrativa

Potencial alto en:

- Resolución de disputas en línea (**ODR**)
- Baremos automatizados en litigios repetitivos o de baja cuantía

**Pero** existe riesgo de “solucionismo digital” que sacrifique el principio de contradicción.

**Ejemplo empírico** (Francia – cortes de Douai y Rennes, 2017):

> El software confundía ocurrencias léxicas simples con causalidades jurídicas profundas → resultados aberrantes.

## 5. El Riesgo Determinista en la Justicia Penal

Máxima reserva por estar en juego la **libertad individual**.

Europa prioriza rehabilitación e individualización de la pena (vs. enfoque actuarial estadounidense – ej. COMPAS con sesgos raciales).

**Garantías irrenunciables**:

- Derecho a un **juez natural** (decisión final humana)
- Derecho a **decisión motivada** (no sustituible por IA)
- Derecho a conocer la **lógica algorítmica** (Convenio 108 modernizado)
- **Prohibición** de aplicar estadísticas grupales a la sanción individual

## 6. Conclusiones: Lagunas en la Investigación y Direcciones Futuras

La IA debe **fortalecer** el Estado de Derecho, no convertirse en fin administrativo.

Estudios (ej. UCL – Aletras et al.) logran ~79% precisión en TEDH, pero basada más en hechos que en razonamiento jurídico complejo.

### Direcciones futuras de investigación

1. Auditoría y certificación externa independiente de algoritmos
2. Ciberética y alfabetización digital para jueces y ciudadanía
3. Análisis del riesgo de estandarización excesiva que bloquee evolución jurisprudencial

---

**Referencias principales**

- CEPEJ (2018). *European Ethical Charter on the Use of Artificial Intelligence in Judicial Systems and their environment*. Council of Europe.
- Ronsin, X., & Lampos, V. (2018). *In-depth study on the use of AI in judicial systems*. Appendix I to the Ethical Charter.
- Aletras, N. et al. (2016). *Predicting judicial decisions of the European Court of Human Rights: a Natural Language Processing perspective*. PeerJ Computer Science.
