---
title: "TSJ Canarias: negligencia disciplinaria por citas jurisprudenciales falsas generadas por IA en recurso de apelación"
date: "2026-02-03"
category: "firma-scarpa"
tags: ["tsj-canarias", "negligencia-profesional", "ia-generativa", "buena-fe-procesal"]
pdf: "/Recursos/Fuentes/Firma-Scarpa/analisis_sentencia_tsj_canarias.pdf"
author: "Ricardo Scarpa"
seoTitle: "Tsj-canarias 2026: TSJ Canarias: | Derecho Artificial"
seoDescription: "El Tribunal Superior de Justicia de Canarias ha acordado formar."
keywords: ["Tsj-canarias", "Negligencia-profesional", "Ia-generativa"]
seoKeyword: "Tsj-canarias"
---

El Tribunal Superior de Justicia de Canarias ha acordado formar pieza separada para investigar la responsabilidad disciplinaria de un letrado que incorporó en un recurso de apelación penal múltiples citas de sentencias del Tribunal Supremo inexistentes o apócrifas, presumiblemente generadas por una herramienta de inteligencia artificial generativa sin verificación alguna. La Sala de lo Penal considera que esta conducta reiterada constituye una infracción grave al deber de veracidad y buena fe procesal (art. 247.3 LEC y art. 542.3 LOPJ), diferenciándola de un mero error aislado. El caso, resuelto en sentencia notificada a inicios de 2026, representa uno de los primeros pronunciamientos judiciales españoles que vincula explícitamente el uso negligente de IA con responsabilidad profesional del abogado.
Contexto y alcance del documento
La Sentencia 126/2025 de la Sala de lo Penal del TSJ de Canarias (ponente: presidente Juan Luis Lorenzo Bragado) confirma la absolución dictada por la Audiencia Provincial de Santa Cruz de Tenerife en un procedimiento por agresión sexual a menor. Al examinar el recurso de apelación interpuesto por la acusación particular, el tribunal detecta numerosas citas jurisprudenciales falsas: al menos siete resoluciones del Tribunal Supremo (con números, fechas y ponentes concretos) y un supuesto informe del CGPJ de 2019 sobre credibilidad del testimonio infantil, ninguno de los cuales existe en bases oficiales (CENDOJ, CURIA, etc.).
El tribunal infiere que las citas, aunque estilísticamente coherentes, son producto de una generación artificial (“lo que el algoritmo le propuso”), y califica la omisión de verificación como “palmaria negligencia”. En lugar de imponer sanción directa, acuerda formar pieza separada (art. 554 LOPJ) para depurar posibles infracciones disciplinarias, garantizando audiencia al letrado.
Claves jurídicas y regulatorias
El pronunciamiento se fundamenta en el marco de buena fe procesal y deberes deontológicos del abogado:

Buena fe procesal (art. 247.3 y 4 LEC): exige diligencia para evitar inducir a error al tribunal; la incorporación reiterada de citas falsas vulnera este principio, aunque no medie dolo.
Deber de buena fe ante órganos jurisdiccionales (art. 542.3 LOPJ): abarca la veracidad de las alegaciones jurídicas; la negligencia grave es suficiente para reproche disciplinario.
Régimen disciplinario (arts. 552-554 LOPJ): permite apercibimiento, multa (300-3.000 €) o suspensión; la pieza separada asegura contradicción y proporcionalidad.
Normativa europea y soft law: se menciona implícitamente la necesidad de supervisión humana efectiva (art. 14 Reglamento UE 2024/1689 – AI Act) y los principales principios del Libro Blanco CGAE-ICAV 2023 (responsabilidad personal, verificación obligatoria, transparencia).

El TSJ distingue claramente entre error venial aislado y negligencia sistemática agravada por confianza ciega en IA, alineándose con precedentes internacionales como Mata v. Avianca (EE.UU., 2023).
Riesgos y obligaciones en la práctica
Para los abogados que incorporen herramientas de IA generativa (LLMs tipo ChatGPT, Claude, etc.) en la redacción de escritos procesales, el caso impone obligaciones reforzadas:

Verificar exhaustivamente toda cita jurisprudencial, normativa o factual en fuentes oficiales antes de incluirla.
Conocer las limitaciones técnicas de los modelos (tendencia a “alucinar” citas plausibles pero falsas, desactualización, falta de acceso real-time a bases jurídicas).
Mantener supervisión humana crítica y documentada (capturas, logs de consulta, registro de prompts y outputs).
Asumir responsabilidad personal íntegra: la firma del escrito implica autoría y veracidad, sin excusa en el “error del algoritmo”.
Informar al cliente sobre el uso de IA cuando pueda afectar confidencialidad o resultado (subida de datos sensibles a plataformas cloud).
Incorporar formación continua sobre riesgos y mejores prácticas de IA en la abogacía.

Incumplir estos deberes puede derivar en:

Sanciones disciplinarias (multa, suspensión).
Multas procesales (180-600 €, art. 247.4 LEC).
Responsabilidad civil (mala praxis) o, en extremos, penal.

Valoración crítica y conclusiones
La sentencia del TSJ de Canarias constituye un precedente relevante y necesario en la jurisprudencia española sobre IA en la abogacía: pone de manifiesto que la tecnología no exime de diligencia profesional y que la reiteración convierte un riesgo técnico conocido en negligencia sancionable. Sin embargo, deja abiertas cuestiones prácticas (umbrales de revisión exigible, protocolos colegiales uniformes, uso admisible de IA como mera herramienta auxiliar) que requerirán desarrollo por colegios profesionales y futuras resoluciones.
Ideas clave para recordar:

La IA generativa es una herramienta útil, pero nunca fuente definitiva sin verificación humana exhaustiva.
El abogado responde personalmente por todo contenido que suscribe, independientemente del origen tecnológico.
La omisión sistemática de contraste de fuentes en escritos que afectan derechos fundamentales justifica apertura de procedimiento disciplinario.

Este caso invita a la abogacía española a acelerar la adopción de protocolos éticos y formativos específicos sobre IA, antes de que nuevos episodios erosionen aún más la credibilidad de la profesión ante los tribunales.

