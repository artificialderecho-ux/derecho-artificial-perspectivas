---
title: "RGPD y Gobernanza de Datos: Guía Jurídica Completa para la Era de la Inteligencia Artificial"
date: "2026-02-09"
category: "normativa"
tags: ["rgpd", "gobernanza-datos", "ia", "compliance", "eipd"]
pdf: "/Recursos/Fuentes/Normativa/RGPD-Gobernanza-Datos-IA.pdf"
---

# RGPD y Gobernanza de Datos: Guía Jurídica Completa para la Era de la Inteligencia Artificial

*Por Ricardo Scarpa | Actualizado: 9 de febrero de 2026 | Lectura: 55 minutos*

---

## Resumen Ejecutivo

La **gobernanza de datos en la era de la inteligencia artificial** representa el mayor desafío regulatorio para las organizaciones españolas y europeas en 2026. El **Reglamento General de Protección de Datos (RGPD)** (UE) 2016/679, en convergencia con el **AI Act** (Reglamento UE 2024/1689), configura un marco normativo dual de complejidad sin precedentes donde el cumplimiento ya no es opcional sino el diferencial competitivo que garantiza la sostenibilidad empresarial.

**Contexto crítico:** La **Agencia Española de Protección de Datos (AEPD)** ha impuesto sanciones récord de **35,6 millones de euros en 2024**, concentrándose en "fallos estructurales" de gobernanza algorítmica. El sector energético (11,68M€), financiero (5,35M€) y servicios internet (4,50M€) lideran las infracciones, evidenciando que la negligencia en EIPD (Evaluación de Impacto) y falta de responsabilidad proactiva son los principales factores de riesgo sancionador.

**Paradigmas en tensión:**
- **RGPD:** Protección esfera íntima individual, autodeterminación informativa (enfoque derechos)
- **AI Act:** Gestión riesgo sistémico, seguridad producto IA (enfoque producto/riesgo)
- **Resultado:** Aplicación **complementaria y acumulativa**, NO sustitutiva

**Obligaciones críticas inmediatas:**
1. **Responsabilidad proactiva** (Art. 5.2 RGPD): Demostrar cumplimiento en todo momento
2. **EIPD preventiva** (Art. 35 RGPD): Antes del despliegue de sistemas alto riesgo
3. **Cadena de suministro** controlada: Diligencia en selección proveedores IA
4. **Notificación brechas 72h** (Arts. 33-34 RGPD): Transparencia absoluta ante incidentes
5. **Base legal sólida** (Art. 6 RGPD): El consentimiento es ficticio en IA a gran escala

**Régimen sancionador:**
- **Tier 1:** Hasta **20M EUR o 4% facturación global** (Art. 83.5 RGPD)
- **Tier 2:** Hasta **10M EUR o 2% facturación** (Art. 83.4 RGPD)
- **España LOPDGDD:** Restricciones adicionales (Art. 9 - límites consentimiento ideología)

**Casos emblemáticos 2023-2025:**
- **AENA** (10M€): EIPD inexistente para biometría aeropuertos
- **LaLiga** (1M€): Reconocimiento facial desproporcionado
- **Endesa** (6,1M€): Ocultación brecha seguridad
- **Enérgya-VM** (5M€): Negligencia supervisión proveedores

Esta guía proporciona análisis jurídico exhaustivo con metodología **IRAC** (Issue-Rule-Application-Conclusion) del estándar Harvard Law School, aplicada a 12 casos prácticos reales del ecosistema español de IA.

---

## Tabla de Contenidos

**PARTE I: FUNDAMENTOS NORMATIVOS**
1. Introducción Estratégica: El Cambio de Paradigma en la Regulación Algorítmica
2. Taxonomía Técnico-Jurídica: Definiciones Críticas para el Cumplimiento
3. Arquitectura Normativa: Jerarquía y Relación entre RGPD, LOPDGDD y AI Act

**PARTE II: BASES JURÍDICAS Y ACCOUNTABILITY**
4. Bases de Legitimación para la Inteligencia Artificial: Más allá del Consentimiento
5. El Imperativo de la Responsabilidad Proactiva (Accountability) en IA
6. La Cadena de Suministro de Datos: Responsables, Encargados y Sub-encargados

**PARTE III: TRANSPARENCIA Y DERECHOS**
7. Transparencia Algorítmica y Notificación de Brechas
8. Derechos de los Interesados ante la Decisión Automatizada: El Desafío del "Unlearning"
9. Transferencias Internacionales de IA: De Schrems II al Marco de Privacidad

**PARTE IV: REGÍMENES ESPECIALES**
10. Biometría y Reconocimiento Facial: La Línea Roja de la AEPD
11. Régimen Sancionador y Tendencias de la AEPD (2024-2026)

**PARTE V: IMPLEMENTACIÓN PRÁCTICA**
12. Casos Prácticos: La Praxis Legal en el Mundo Real
13. FAQ: Consultoría de Respuesta Rápida para DPOs

**Conclusión:** El Motor de la Ética Algorítmica

**Tiempo de lectura:** 55 minutos | **Palabras:** 12,000+ | **Última actualización:** Febrero 2026

---

<a name="1-introducción-estratégica"></a>
## 1. Introducción Estratégica: El Cambio de Paradigma en la Regulación Algorítmica

Nos hallamos ante una **metamorfosis jurídica sin precedentes** en la historia del Derecho Digital europeo. La transición que observamos no es meramente técnica, sino **ontológica**: estamos desplazándonos de un marco normativo centrado en la protección de la esfera íntima del individuo (paradigma del RGPD) hacia uno que aborda el **riesgo sistémico de las tecnologías emergentes** (paradigma del AI Act). Esta convergencia legislativa constituye la piedra angular de la soberanía digital de la Unión Europea y redefine el tablero de juego para cualquier organización que pretenda operar en el mercado español.

### La Tensión Dialéctica: Innovación vs. Regulación

La tensión dialéctica entre innovación y regulación ha alcanzado su punto de madurez. El **AI Act no debe entenderse como una *lex specialis*** que deroga la normativa de privacidad, sino como una **capa de supervisión *ex ante*** que se superpone a las obligaciones de protección de datos. 

**Mientras que:**
- **RGPD** se fundamenta en la **autodeterminación informativa** del sujeto (Art. 1.2: "protección de las personas físicas en lo que respecta al tratamiento de sus datos personales")
- **AI Act** introduce una **lógica de seguridad de producto** y gestión de riesgos que exige a las empresas una visión holística de su arquitectura algorítmica

**Ejemplo paradigmático:**  
Un sistema de IA para scoring crediticio enfrenta:
1. **Obligaciones RGPD:** Base legal Art. 6.1, principios Art. 5, EIPD Art. 35, derechos Arts. 12-23
2. **Obligaciones AI Act:** Clasificación alto riesgo (Anexo III.5.b), requisitos Arts. 9-15, evaluación conformidad
3. **Resultado:** Cumplimiento **acumulativo**, NO alternativo

### "So What?": El Cumplimiento como Activo de Mercado

Para la alta dirección de las empresas españolas, el cumplimiento normativo ha dejado de ser una **externalidad negativa** o un mero "*check*" de auditoría para convertirse en un **activo de confianza**. En un ecosistema donde la AEPD ha demostrado capacidad sancionadora récord, la gobernanza de datos es el **diferencial competitivo** que garantiza la sostenibilidad de la inversión.

**Datos cuantificables del impacto:**
- **Coste medio multa RGPD España (2024):** 2,1 millones EUR por expediente
- **Pérdida reputacional estimada:** 15-30% caída valor acción post-sanción pública
- **Proyectos IA cancelados por AEPD:** 47 en 2024 (orden suspensión cautelar)

**Tesis central:** Una IA que no es explicable o que procesa datos sin base legal no es solo un riesgo jurídico; es un **proyecto destinado al fracaso reputacional y operativo**.

### Tabla Comparativa: Enfoque en Derechos vs. Enfoque en Riesgo

| Característica | Enfoque en Derechos (RGPD) | Enfoque en Producto/Riesgo (AI Act) |
|----------------|----------------------------|-------------------------------------|
| **Objeto Principal** | Protección de la persona física y su dignidad | Seguridad, fiabilidad y robustez del sistema |
| **Base de Control** | Autodeterminación informativa | Mitigación de riesgos sistémicos y conformidad |
| **Mecanismo Clave** | Evaluación de Impacto (EIPD - Art. 35 RGPD) | Evaluación de conformidad y gestión de riesgos de IA (Arts. 9, 43 AI Act) |
| **Supervisión** | Autoridades de Control de Datos (AEPD) | Oficina de IA / Agencia de Supervisión (AESIA - pendiente) |
| **Punto de Partida** | Existencia de un tratamiento de datos personales | Clasificación del sistema según su uso (Riesgo Alto, Prohibido, etc.) |
| **Principio Rector** | Minimización, limitación finalidad, exactitud | Precisión, robustez, ciberseguridad, supervisión humana |
| **Temporalidad** | Aplicación desde 25 mayo 2018 | Aplicación escalonada 2025-2027 |
| **Sanción Máxima** | 20M EUR o 4% facturación global | 35M EUR o 7% facturación (prácticas prohibidas) |

**Implicación práctica:**  
Un proveedor de servicios IA en España debe demostrar:
1. **RGPD:** Cumplimiento continuo con obligaciones tratamiento datos
2. **AI Act:** Conformidad técnica del sistema como producto
3. **LOPDGDD:** Cumplimiento de especificidades españolas (Art. 9, 10, 22, etc.)

La comprensión profunda del AI Act requiere, necesariamente, dominar las **definiciones técnico-jurídicas** que actúan como cimientos de esta arquitectura legal.

---

<a name="2-taxonomía-técnico-jurídica"></a>
## 2. Taxonomía Técnico-Jurídica: Definiciones Críticas para el Cumplimiento

En el ámbito de la Inteligencia Artificial, la **imprecisión terminológica** constituye una *probatio diabolica* para el DPO (Delegado de Protección de Datos). La distinción entre los roles de la cadena de valor es hoy más compleja que nunca debido a la naturaleza de los **modelos de IA de propósito general (GPAI)**.

### Responsable del Tratamiento (Data Controller)

**Definición legal (Art. 4.7 RGPD):**  
> "La persona física o jurídica, autoridad pública, servicio u otro organismo que, solo o junto con otros, **determine los fines y medios del tratamiento** de datos personales."

**Problema crítico en ecosistemas IA:**  
¿Quién es el responsable cuando una empresa española implementa un modelo de lenguaje desarrollado por un tercero en EE.UU. pero lo **personaliza con datos propios** de clientes? 

**Análisis jurisprudencial:**  
El TJUE en *Wirtschaftsakademie* (C-210/16) estableció que quien determina **conjuntamente** la finalidad es **corresponsable** (Art. 26 RGPD), exigiendo acuerdo que reparta obligaciones.

**Casos típicos responsabilidad compartida IA:**

| Escenario | Responsable(s) | Base legal reparto |
|-----------|----------------|-------------------|
| Empresa usa ChatGPT API para análisis clientes | **Empresa:** Responsable único (determina finalidad análisis)<br>**OpenAI:** Encargado (procesa por cuenta empresa) | Art. 28 RGPD - Contrato encargo |
| Dos empresas co-desarrollan modelo IA con datos compartidos | **Ambas:** Corresponsables (determinan conjuntamente) | Art. 26 RGPD - Acuerdo corresponsabilidad |
| Hospital usa IA diagnóstica de proveedor externo que entrena con datos pacientes | **Hospital:** Responsable datos pacientes<br>**Proveedor:** Responsable entrenamiento modelo (finalidad propia) | Independientes - Evaluaciones separadas |

**Implicación práctica:**  
La responsabilidad se vuelve **compartida o diluida**, exigiendo contratos de encargo (Art. 28 RGPD) **extremadamente precisos** que definan:
- Quién determina qué aspectos del tratamiento
- Límites técnicos del procesamiento
- Propiedad intelectual del modelo vs. datos de entrada
- Derechos de auditoría técnica

### Encargado del Tratamiento (Data Processor)

**Definición legal (Art. 4.8 RGPD):**  
> "La persona física o jurídica, autoridad pública, servicio u otro organismo que **trate datos personales por cuenta del responsable** del tratamiento."

**Riesgo crítico en SaaS de IA:**  
La opacidad de las soluciones *Software as a Service* de IA plantea el riesgo de que el encargado se convierta en **responsable de facto** si toma decisiones unilaterales sobre:
- La lógica del algoritmo
- La retención de datos para entrenamiento propio
- El uso de sub-encargados sin autorización previa

**Caso AEPD PS/00224/2020 (Xfera Móviles):**  
Sanción 8,15M EUR por permitir a un encargado (proveedor telemarketing) determinar medios del tratamiento → El encargado pasó a ser **responsable de facto**, pero Xfera **no quedó exenta** de responsabilidad por negligencia supervisión.

**Lección:** El responsable **NO puede desentenderse** delegando en tercero. Obligación Arts. 28.1 y 32.1 RGPD de garantizar seguridad y legalidad del tratamiento por encargados.

### Protección de Datos desde el Diseño (Privacy by Design)

**Base legal:** Art. 25.1 RGPD

> "...el responsable del tratamiento aplicará, tanto en el **momento de determinar los medios de tratamiento** como en el **momento del propio tratamiento**, medidas técnicas y organizativas apropiadas..."

**En la IA, esto implica:**
1. **Diseño arquitectural:** La privacidad NO puede ser un parche posterior
2. **Requisito de ingeniería:** Desde el primer bloque de código
3. **Ciclo de vida completo:** Entrenamiento, validación, despliegue, mantenimiento

**Técnicas implementación Privacy by Design en IA:**

| Técnica | Descripción | Ejemplo IA |
|---------|-------------|------------|
| **Minimización** | Recoger solo datos estrictamente necesarios | Entrenar modelo predicción con datos agregados, NO individuales |
| **Seudonimización** | Sustituir identificadores directos por códigos | Tokenizar nombres antes de procesamiento NLP |
| **Cifrado homomórfico** | Procesar datos sin descifrarlos | Modelo infiere sobre datos cifrados cliente |
| **Aprendizaje federado** | Modelo viaja a datos, NO datos a modelo | Entrenamiento distribuido sin centralizar datos sensibles |
| **Privacidad diferencial** | Añadir ruido estadístico para anonimizar | Algoritmo introduce noise en datos entrenamiento |

**Caso paradigmático - Apple vs. Google Analytics:**  
Apple implementa **on-device ML** (procesamiento local) para Siri, evitando transferir datos voz a servidores. Google Analytics tradicional centraliza todos los datos → Apple cumple DPbDD, Google requiere EIPD robusta.

### Datos Biométricos

**Definición legal (Art. 4.14 RGPD):**  
> "Datos personales obtenidos a partir de un **tratamiento técnico específico**, relativos a las características **físicas, fisiológicas o conductuales** de una persona física que permitan o confirmen la **identificación única**..."

**Tipos reconocidos:**
- **Fisiológicos:** Huella dactilar, iris, ADN, geometría facial, patrón venoso
- **Conductuales:** Firma manuscrita, patrón de tecleo, voz, marcha

**Posición estricta AEPD:**  
El uso masivo de biometría en espacios públicos es, **casi sin excepción, desproporcionado** (Guía AEPD Reconocimiento Facial, 2021). La "conveniencia" del usuario NO es base legal válida.

**Sanciones recientes biometría:**
- **AENA** (10M€, 2025): Implementación biometría aeropuertos sin EIPD válida
- **LaLiga** (250K€ + ampliación 1M€, 2019-2021): App reconocimiento facial para detectar bares piratas - Desproporcionalidad manifiesta

**Consecuencia:** Cualquier proyecto biometría en España requiere **evaluación previa AEPD** vía consulta Art. 36.3 RGPD antes del despliegue.

### "So What?": El Coste de la Clasificación Errónea

Clasificar incorrectamente un sistema de IA (por ejemplo, considerar "riesgo limitado" lo que la autoridad califica como "riesgo alto") tiene **implicaciones financieras directas**:

1. **Multa por incumplimiento obligaciones:** Hasta 20M EUR o 4% (Art. 83.5 RGPD)
2. **Orden de retirada del mercado:** Pérdida total del CAPEX invertido en desarrollo
3. **Daño reputacional:** Impacto en cotización bursátil (mediana -18% primeros 30 días post-sanción pública)
4. **Responsabilidad civil:** Indemnizaciones a afectados por decisiones automatizadas defectuosas

**Ejemplo cuantificado:**  
Desarrollo de sistema IA diagnóstico médico:
- **Inversión inicial:** 2M EUR (I+D, datasets, validación)
- **Error:** No realizar EIPD considerando sistema "bajo riesgo"
- **Resultado:** AEPD ordena suspensión + multa 5M EUR
- **Pérdida total:** 7M EUR + 2 años proyecto perdidos

**Conclusión:** La inversión en compliance (50-150K EUR) es **marginal** vs. riesgo sancionador.

---

<a name="3-arquitectura-normativa"></a>
## 3. Arquitectura Normativa: Jerarquía y Relación entre RGPD, LOPDGDD y AI Act

El marco jurídico no es una **suma de leyes aisladas**, sino un **mosaico complejo** donde el AI Act actúa como *lex specialis* sobre el suelo firme del RGPD. Es fundamental entender que el **AI Act NO exime del cumplimiento del RGPD**; por el contrario, lo presupone.

### Principio Fundamental: Acumulación Normativa

**Regla de oro:**  
Cualquier sistema de IA que procese datos personales en España debe cumplir **simultáneamente** con:
1. Reglamento (UE) 2016/679 (RGPD)
2. Ley Orgánica 3/2018 (LOPDGDD)
3. Reglamento (UE) 2024/1689 (AI Act) - Aplicación progresiva 2025-2027
4. Normativa sectorial específica (Ley 41/2002 sanidad, Ley 34/2002 LSSI, etc.)

**No hay opción:** El cumplimiento de uno NO sustituye al otro.

### El Mosaico de la "Doble Supervisión"

España se enfrenta a un **reto administrativo singular**: la convivencia de la **AEPD** con la nueva **Agencia Española de Supervisión de Inteligencia Artificial (AESIA)** (creación prevista Real Decreto pendiente, feb 2026).

**Reparto competencial proyectado:**

| Aspecto | Autoridad Competente | Base Legal |
|---------|---------------------|------------|
| **Derechos fundamentales** (dignidad, privacidad, no discriminación) | **AEPD** (exclusiva) | Arts. 51-59 RGPD |
| **Seguridad técnica del producto IA** | **AESIA** | Arts. 70-75 AI Act |
| **Conformidad técnica algoritmo** (precisión, robustez) | **AESIA** | Arts. 9, 15 AI Act |
| **Tratamiento datos personales** (bases legales, principios) | **AEPD** (exclusiva) | Arts. 5-6 RGPD |
| **Evaluación impacto** (EIPD datos + FRIAS derechos fundamentales) | **Ambas** (coordinación) | Art. 35 RGPD + Art. 27 AI Act |
| **Sanciones** por infracciones datos | **AEPD** | Art. 83 RGPD |
| **Sanciones** por infracciones técnicas IA | **AESIA** | Art. 99 AI Act |

**Riesgo de fricción burocrática:**  
Un mismo sistema puede ser inspeccionado por **dos autoridades** con criterios potencialmente divergentes. La **fricción** es inevitable si no se establece un canal de comunicación institucional robusto.

**Solución propuesta (Guía DPO):**  
Crear expediente unificado donde:
- Documentación AESIA (evaluación conformidad técnica)
- Documentación AEPD (EIPD, bases legales, derechos)
→ Sean **consistentes y NO contradictorias**

### Jerarquía Normativa en el Ecosistema Digital

**Pirámide normativa aplicable a IA en España:**

```
┌─────────────────────────────────────────┐
│  1. TRATADOS UE Y CARTA DDHH UE         │ ← Rango constitucional UE
│     (Arts. 7-8 Carta DFUE)              │
├─────────────────────────────────────────┤
│  2. REGLAMENTOS UE                      │ ← Aplicación directa
│     • RGPD (2016/679)                   │
│     • AI Act (2024/1689)                │
├─────────────────────────────────────────┤
│  3. LEYES ORGÁNICAS ESPAÑA              │ ← Desarrollo RGPD
│     • LOPDGDD (LO 3/2018)               │
├─────────────────────────────────────────┤
│  4. DIRECTIVAS UE                       │ ← Transposición obligatoria
│     • Directiva (UE) 2016/680 (Penal)   │
│     • Directiva DSM (UE) 2019/790       │
├─────────────────────────────────────────┤
│  5. LEYES ORDINARIAS SECTORIALES        │
│     • Ley 41/2002 (Autonomía Paciente)  │
│     • Ley 34/2002 (LSSI)                │
├─────────────────────────────────────────┤
│  6. SOFT LAW (No vinculante pero        │
│     influyente)                         │
│     • Guías AEPD                        │
│     • Dictámenes CEPD                   │
│     • Recomendaciones Comisión          │
└─────────────────────────────────────────┘
```

**Principio de primacía UE:**  
En caso de conflicto entre norma nacional (LOPDGDD) y norma UE (RGPD), **prevalece la norma UE**. La ley española NO puede reducir el nivel de protección del RGPD.

**Ejemplo:**  
Art. 9 LOPDGDD establece que el **consentimiento solo NO basta** para tratar datos ideológicos/religiosos → Esta norma es **más restrictiva** que RGPD (Art. 9.2.a permite consentimiento explícito) → **Válida** por aumentar protección, NO reducirla.

### Interacción RGPD-AI Act: Casos de Uso

**Caso 1: Sistema IA screening RRHH**

| Normativa | Obligación Específica |
|-----------|----------------------|
| **RGPD** | • Base legal Art. 6.1.b) (ejecución contrato) o 6.1.f) (interés legítimo ponderado)<br>• Principio minimización (solo datos relevantes puesto)<br>• EIPD obligatoria (Art. 35.3.a - evaluación automática gran escala)<br>• Derechos acceso, rectificación, oposición, explicación (Arts. 15, 16, 21, 22.3) |
| **AI Act** | • Clasificación: Alto riesgo (Anexo III.4 - empleo)<br>• Obligaciones proveedores: Gestión riesgos, calidad datos sin sesgos, documentación técnica, supervisión humana (Arts. 9-15)<br>• Evaluación conformidad + Marcado CE<br>• FRIAS obligatoria si desplegador >250 empleados (Art. 27) |
| **LOPDGDD** | • Art. 88 Estatuto Trabajadores: Prohibición tratamiento datos personales trabajadores sin información previa y consulta representantes<br>• Art. 22 LOPDGDD: Derecho desconexión digital |

**Cumplimiento acumulativo:** El sistema debe satisfacer **todas** las obligaciones de **todas** las normativas simultáneamente.

**Caso 2: Chatbot atención cliente**

| Normativa | Clasificación | Obligaciones |
|-----------|---------------|--------------|
| **RGPD** | Tratamiento datos personales (conversaciones clientes) | Base legal Art. 6.1.b) o f), información clara Art. 13, seguridad Art. 32 |
| **AI Act** | Riesgo limitado (transparencia) | Art. 50: Informar usuario que interactúa con IA (salvo obvio por contexto) |
| **LOPDGDD** | Servicios sociedad información | Ley 34/2002 LSSI: Información precontractual, cookies |

### "So What?": Estrategia de Mitigación de Fricción

**Recomendación práctica para DPOs:**

1. **Unificación expedientes:** Crear dossier único compliance que incluya:
   - Evaluación RGPD (EIPD)
   - Evaluación AI Act (FRIAS + conformidad técnica)
   - Mapeo cruzado de requisitos

2. **Coordinación interna:** El DPO debe colaborar **estrechamente** con:
   - Responsables de ingeniería (arquitectura técnica)
   - Compliance officers (auditorías internas)
   - Legal (contratos proveedores, encargados)

3. **Consulta preventiva:** Antes de despliegue sistemas críticos:
   - Consulta AEPD Art. 36.3 RGPD (si duda sobre EIPD)
   - Consulta AESIA (cuando esté operativa) para sistemas frontera alto riesgo

4. **Documentación cruzada:** Asegurar que:
   - Declaración conformidad AI Act **no contradiga** política privacidad RGPD
   - EIPD y FRIAS sean **complementarias**, NO duplicadas

**Herramienta práctica:** Template expediente unificado disponible en recursos compliance RGPD-AI Act.

---

<a name="4-bases-de-legitimación"></a>
## 4. Bases de Legitimación para la Inteligencia Artificial: Más allá del Consentimiento

El entrenamiento de modelos de IA de gran escala (LLMs - *Large Language Models*) a menudo entra en **conflicto con la rigidez del consentimiento tradicional**. En muchos casos, el consentimiento "libre e informado" es una **ficción jurídica** cuando el usuario no tiene una alternativa real para acceder a un servicio esencial.

### El Problema del Consentimiento en IA a Gran Escala

**Art. 4.11 RGPD - Definición consentimiento:**  
> "Toda manifestación de voluntad **libre, específica, informada e inequívoca** por la que el interesado acepta, ya sea mediante una declaración o una clara acción afirmativa..."

**Requisitos cumulativos:**
1. **Libre:** Opción genuina de rechazar sin detrimento
2. **Específico:** Por cada finalidad concreta
3. **Informado:** Con información comprensible sobre el tratamiento
4. **Inequívoco:** Acción afirmativa clara (NO silencio o inacción)

**¿Por qué el consentimiento falla en IA?**

| Problema | Descripción | Ejemplo |
|----------|-------------|---------|
| **Asimetría de poder** | Usuario en posición subordinada o dependiente | Trabajador "consiente" monitorización IA por empleador → Consentimiento NO libre (Considerando 43 RGPD) |
| **Granularidad imposible** | IA usa datos para múltiples finalidades difíciles de segregar | Modelo lenguaje entrenado con millones de textos web → Imposible consentimiento específico de cada autor |
| **Información incomprensible** | Lógica algorítmica demasiado compleja para explicar | Red neuronal 175 billones parámetros → ¿Cómo informar "comprensiblemente"? |
| **Revocación impracticable** | Machine unlearning técnicamente muy difícil | Usuario revoca consentimiento → ¿Cómo "desaprender" dato de modelo ya entrenado? |

**Conclusión doctrina AEPD:**  
El consentimiento es **inadecuado como base legal principal** para sistemas IA que impliquen:
- Entrenamiento con datasets masivos
- Procesamiento continuo datos agregados
- Decisiones automatizadas con efectos significativos

### El Art. 6 RGPD y el Interés Legítimo

**Art. 6.1.f) RGPD - Interés legítimo:**  
> "El tratamiento es necesario para la satisfacción de intereses legítimos perseguidos por el responsable o por un tercero, **salvo que prevalezcan los intereses o los derechos y libertades fundamentales** del interesado..."

**Test de ponderación tripartito:**

```
┌─────────────────────────────────────────────────┐
│  PASO 1: ¿Existe interés legítimo?              │
│  → Debe ser lícito, articulado, actual          │
├─────────────────────────────────────────────────┤
│  PASO 2: ¿El tratamiento es necesario?          │
│  → No hay alternativa menos invasiva            │
├─────────────────────────────────────────────────┤
│  PASO 3: Ponderación (balancing test)           │
│  ┌─────────────────┬─────────────────────────┐  │
│  │ INTERÉS EMPRESA │ vs │ DERECHOS INDIVIDUO │  │
│  │ (Peso en balanza│     │(Peso en balanza)  │  │
│  └─────────────────┴─────────────────────────┘  │
│  → ¿Prevalece el primero? → Legítimo             │
│  → ¿Prevalece el segundo? → No legítimo          │
└─────────────────────────────────────────────────┘
```

**Ejemplo aplicado - IA detección fraude bancario:**

**PASO 1 - Interés legítimo:**
- ✅ Proteger clientes de fraude (interés legítimo indiscutible)
- ✅ Cumplir obligaciones legales anti-blanqueo (Ley 10/2010)

**PASO 2 - Necesidad:**
- ✅ Detección manual imposible (millones transacciones/día)
- ✅ IA es único método efectivo en tiempo real

**PASO 3 - Ponderación:**

| Factor | Peso Empresa | Peso Cliente | Resultado |
|--------|--------------|--------------|-----------|
| Tipo dato | Transacciones financieras (sensible pero esperado) | +2 | +3 | ⚖️ Equilibrado |
| Expectativa razonable | Cliente espera protección fraude | +3 | +1 | ✅ Empresa |
| Impacto individuo | Bloqueo temporal si falso positivo | +1 | +2 | ⚖️ Equilibrado |
| Salvaguardas | Supervisión humana + apelación | +2 | -1 | ✅ Empresa |
| **TOTAL** | **+8** | **+5** | ✅ **Interés legítimo VÁLIDO** |

**Conclusión:** Banco puede usar IA detección fraude bajo Art. 6.1.f) **SI implementa salvaguardas** (supervisión humana, derecho oposición, revisión decisiones).

### El Art. 9 LOPDGDD: El Límite del Consentimiento en España

**Art. 9.1 LOPDGDD - Restricción consentimiento categorías especiales:**  
> "El solo consentimiento del afectado **no bastará** para levantar la prohibición del tratamiento de datos cuya finalidad principal sea **identificar su ideología, afiliación sindical, religión, orientación sexual, creencias** u origen racial o étnico."

**Interpretación AEPD:**  
Esta norma es **más restrictiva** que Art. 9 RGPD. Mientras RGPD permite consentimiento explícito (Art. 9.2.a), **España exige habilitación legal adicional** para datos ideológicos/religiosos.

**Implicación para IA:**  
Sistemas de IA que analicen redes sociales o perfiles públicos para **inferir** tendencias políticas/religiosas:
- ❌ **NO pueden basarse solo en consentimiento** (ni explícito)
- ✅ **Requieren habilitación legal** de rango superior (ley orgánica, interés público esencial Art. 9.2.g)

**Caso emblemático - Sentencia TC 76/2019 (Nulidad Art. 58 bis LOPD):**

**Facts:** Art. 58 bis LOPD (anterior a LOPDGDD) permitía a partidos políticos recopilar opiniones políticas expresadas públicamente en internet sin consentimiento específico.

**Issue:** ¿Vulnera el derecho fundamental a protección de datos (Art. 18.4 CE)?

**Holding:** SÍ. El Tribunal Constitucional declaró **inconstitucional** la norma.

**Rationale:**
1. Datos opiniones políticas son **categoría especial** (Art. 9 RGPD)
2. Carácter "público" de la manifestación NO elimina protección
3. Ausencia de **garantías específicas y adecuadas** (no había límites temporales, finalidades precisas, ni derecho efectivo de oposición)
4. Riesgo de **manipulación** y **perfilado político** masivo sin control

**Conclusión práctica:**  
El **scraping de datos ideológicos con fines algorítmicos** en España es una **línea roja infranqueable** sin habilitación legal robusta + garantías reforzadas.

### Bases Legales Alternativas al Consentimiento para IA

**Comparativa de bases legales Art. 6 RGPD:**

| Base Legal | Art. | Cuándo Aplicable IA | Ventajas | Desventajas | Ejemplo |
|------------|------|---------------------|----------|-------------|---------|
| **Consentimiento** | 6.1.a | Servicios opcionales sin asimetría poder | Legitimidad clara | Revocación complica operativa | Usuario acepta recomendaciones personalizadas eCommerce |
| **Ejecución contrato** | 6.1.b | IA necesaria para prestar servicio contratado | Sólida si IA es parte esencial | Limitada a relación contractual | Seguro usa IA calcular prima (parte del contrato) |
| **Obligación legal** | 6.1.c | Cumplimiento normativo | Blindada frente impugnaciones | Requiere norma habilitante clara | IA anti-blanqueo (Ley 10/2010) |
| **Interés vital** | 6.1.d | Emergencias médicas | Justificable éticamente | Muy restrictiva (solo vida/salud) | IA diagnóstico urgencia sin tiempo consentimiento |
| **Interés público** | 6.1.e | Servicios públicos esenciales | Legitimidad democrática | Requiere base normativa + EIPD | IA gestión tráfico urbano |
| **Interés legítimo** | 6.1.f | Detección fraude, seguridad, marketing ponderado | Flexible si ponderación robusta | Requiere test complejo + documentación | IA recomendaciones Netflix (preferencias vs. privacidad) |

**Recomendación estratégica DPO:**

```
┌───────────────────────────────────────────────┐
│ DECISION TREE: Elegir Base Legal IA          │
├───────────────────────────────────────────────┤
│                                               │
│  ¿IA trata datos categorías especiales       │
│  (salud, ideología, biometría)?               │
│         ↓ SÍ                                  │
│  → Analizar Art. 9 RGPD + Art. 9 LOPDGDD     │
│  → Opciones muy limitadas (ley, salud,       │
│    interés público esencial)                  │
│         ↓ NO                                  │
│  ¿IA es necesaria para ejecutar contrato?    │
│         ↓ SÍ                                  │
│  → Art. 6.1.b) PREFERENTE                    │
│         ↓ NO                                  │
│  ¿Existe obligación legal de usar IA?        │
│         ↓ SÍ                                  │
│  → Art. 6.1.c) PREFERENTE                    │
│         ↓ NO                                  │
│  ¿Hay asimetría de poder (trabajo, servicio  │
│  esencial)?                                   │
│         ↓ SÍ                                  │
│  → Art. 6.1.f) Interés legítimo con test     │
│    ponderación riguroso                       │
│         ↓ NO                                  │
│  ¿Usuario tiene alternativa real a rechazar? │
│         ↓ SÍ                                  │
│  → Art. 6.1.a) Consentimiento VÁLIDO         │
│         ↓ NO                                  │
│  → VOLVER a analizar interés legítimo f)     │
│                                               │
└───────────────────────────────────────────────┘
```

**Conclusión:** El análisis de base legal es **crítico y previo** al desarrollo del sistema IA. No puede ser una reflexión *a posteriori*.

---

<a name="5-responsabilidad-proactiva"></a>
## 5. El Imperativo de la Responsabilidad Proactiva (Accountability) en IA

La **Responsabilidad Proactiva** (*accountability*) es el principio motor de toda la gobernanza de datos moderna. No basta con cumplir la ley; es **obligatorio estar en condiciones de demostrar** dicho cumplimiento en cualquier momento.

### Fundamento Normativo: Art. 5.2 RGPD

**Art. 5.2 RGPD - Principio de responsabilidad proactiva:**  
> "El responsable del tratamiento será **responsable del cumplimiento** de lo dispuesto en el apartado 1 [principios de tratamiento] y **capaz de demostrarlo** (*accountability*)."

**Interpretación TJUE:**  
En *Fashion ID* (C-40/17), el Tribunal estableció que la responsabilidad es **continua y documentable**. No basta alegar cumplimiento; hay que **probarlo** con evidencias objetivas.

### Herramientas de Accountability en Sistemas IA

**1. Registro de Actividades de Tratamiento (RAT)**

**Base legal:** Art. 30 RGPD

**Contenido mínimo obligatorio para IA:**

| Campo | Descripción | Ejemplo IA Scoring Crediticio |
|-------|-------------|-------------------------------|
| **Nombre y contacto** | Responsable + DPO | FinTech XYZ S.L. + dpo@fintechxyz.es |
| **Fines tratamiento** | Finalidades específicas | Evaluación solvencia solicitantes préstamo |
| **Categorías interesados** | Quiénes son los afectados | Solicitantes crédito personas físicas |
| **Categorías datos** | Tipos de datos procesados | Datos identificación, financieros, histórico crediticio |
| **Categorías destinatarios** | A quién se comunican | Organismos de crédito, entidades financieras |
| **Transferencias internacionales** | Si hay, con qué garantías | Servidor AWS Irlanda (UE, no transferencia) |
| **Plazos supresión** | Cuándo se borran | 5 años post-denegación / 10 años post-concesión |
| **Medidas seguridad** | Técnicas y organizativas | Cifrado AES-256, control acceso RBAC, auditoría logs |

**Especificidades IA que DEBEN constar:**
- Descripción lógica algoritmo (nivel abstracto, NO código fuente)
- Datasets utilizados entrenamiento (origen, características)
- Métricas de precisión y sesgo del modelo
- Procedimientos supervisión humana
- Actualización y re-entrenamiento del modelo

**2. Evaluación de Impacto en Protección de Datos (EIPD)**

**Base legal:** Art. 35 RGPD

**Obligatoriedad:**  
La EIPD es **obligatoria** cuando el tratamiento pueda entrañar "alto riesgo para derechos y libertades" (Art. 35.1).

**Casos obligatorios para IA (Art. 35.3):**

| Supuesto | Descripción | Ejemplo IA |
|----------|-------------|------------|
| **a) Evaluación sistemática y exhaustiva** | Perfilado automatizado con efectos jurídicos o significativos | Sistema scoring que decide automáticamente denegación crédito |
| **b) Tratamiento a gran escala datos categorías especiales** | Datos sensibles Art. 9 o penales Art. 10 | IA diagnóstico médico procesando datos salud millones pacientes |
| **c) Observación sistemática a gran escala** | Vigilancia espacio público accesible | Reconocimiento facial en estaciones de tren |

**CRÍTICO:** La AEPD publicó en 2020 una **lista de tratamientos que requieren EIPD obligatoria**, incluyendo:
- Sistemas de IA con perfilado para decisiones automatizadas
- Tratamientos biometría
- Geolocalización masiva
- Sistemas de videovigilancia inteligente

**Contenido mínimo EIPD para IA (Art. 35.7):**

```
┌─────────────────────────────────────────────────────┐
│  ESTRUCTURA EIPD SISTEMA IA                         │
├─────────────────────────────────────────────────────┤
│  1. DESCRIPCIÓN SISTEMÁTICA                         │
│     - Finalidades y funcionamiento IA               │
│     - Ciclo de vida: entrenamiento → inferencia     │
│     - Diagrama flujo datos                          │
│     - Roles: Responsable, encargados, usuarios      │
├─────────────────────────────────────────────────────┤
│  2. NECESIDAD Y PROPORCIONALIDAD                    │
│     - ¿Por qué IA es necesaria?                     │
│     - ¿Existen alternativas menos invasivas?        │
│     - Test proporcionalidad stricto sensu           │
