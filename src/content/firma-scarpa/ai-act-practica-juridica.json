{
  "title": "El AI Act y la práctica jurídica en Europa: obligaciones reales y riesgos",
  "description": "Análisis jurídico del Reglamento Europeo de IA: obligaciones operativas, zonas grises y riesgos para despachos y departamentos legales.",
  "datePublished": "2025-01-14",
  "author": "Ricardo Scarpa",
  "body": "Un análisis jurídico del Reglamento Europeo de Inteligencia Artificial desde la perspectiva de su aplicación práctica en despachos, departamentos legales e instituciones públicas. Más allá del texto normativo: obligaciones operativas, interacción con el RGPD y cuestiones pendientes de desarrollo.\n\n## 1. Introducción\n\nEl Reglamento (UE) 2024/1689, conocido como AI Act o Reglamento Europeo de Inteligencia Artificial, ha entrado en vigor con la ambición de constituirse como el primer marco jurídico horizontal y vinculante para la regulación de sistemas de inteligencia artificial en una jurisdicción de relevancia global. Su aprobación, tras un prolongado proceso legislativo que se extendió desde la propuesta inicial de la Comisión en abril de 2021, representa un hito normativo cuyas implicaciones prácticas apenas comienzan a desplegarse.\n\nSin embargo, sería un error conceptual significativo abordar el AI Act como una cuestión exclusivamente tecnológica. El Reglamento no regula la tecnología en abstracto, sino su inserción en contextos sociales, económicos e institucionales específicos. Para el sector jurídico, esto tiene una consecuencia directa: el cumplimiento del AI Act no es un problema que pueda delegarse íntegramente a departamentos técnicos o proveedores externos. Se trata de una cuestión organizativa, contractual y, en última instancia, de gobernanza profesional.\n\nEste análisis examina el Reglamento desde la perspectiva de su aplicación práctica en el ejercicio profesional del Derecho. El objetivo no es ofrecer una exposición sistemática de su contenido normativo —tarea ya abordada en otros análisis de este proyecto editorial—, sino identificar las obligaciones reales que recaen sobre despachos, departamentos legales e instituciones, señalar las zonas grises pendientes de clarificación y evaluar los riesgos operativos que el nuevo marco introduce.\n\nLa perspectiva adoptada es deliberadamente prudente. El AI Act es un instrumento normativo complejo, cuya aplicación efectiva dependerá de un ecosistema regulatorio aún en construcción: guías de la Comisión, estándares técnicos armonizados, interpretaciones de las autoridades nacionales competentes y, eventualmente, jurisprudencia de los tribunales europeos y nacionales. Cualquier afirmación categórica sobre el alcance de determinadas obligaciones debe, por tanto, formularse con la cautela que impone un marco normativo en fase de despliegue inicial.\n\n## 2. El enfoque basado en riesgo del Reglamento Europeo de IA\n\nLa arquitectura normativa del AI Act se sustenta sobre un principio de proporcionalidad regulatoria: las obligaciones impuestas a los operadores económicos se gradúan en función del nivel de riesgo que el sistema de IA representa para la seguridad, la salud y los derechos fundamentales de las personas. Esta técnica regulatoria, inspirada en modelos consolidados en otros ámbitos del Derecho de la Unión, permite evitar una aproximación homogénea que resultaría desproporcionada para sistemas de bajo impacto e insuficiente para aplicaciones de alta sensibilidad.\n\nEl Reglamento establece cuatro categorías de riesgo con consecuencias jurídicas diferenciadas. En primer lugar, los sistemas de riesgo inaceptable, enumerados de forma taxativa en el artículo 5, quedan directamente prohibidos. Se incluyen en esta categoría prácticas como la manipulación subliminal, la explotación de vulnerabilidades de grupos específicos, la puntuación social por parte de autoridades públicas y determinados usos de identificación biométrica en tiempo real en espacios públicos. La prohibición es absoluta, sin perjuicio de excepciones muy tasadas vinculadas a fines de seguridad pública.\n\nEn segundo lugar, los sistemas de alto riesgo constituyen el núcleo sustantivo del régimen regulatorio. Su identificación se realiza mediante una técnica de doble lista: por un lado, sistemas integrados en productos sujetos a legislación de armonización de la Unión (Anexo I); por otro, sistemas utilizados en ámbitos especialmente sensibles enumerados en el Anexo III. Este segundo anexo resulta de especial relevancia para el sector jurídico, al incluir expresamente aplicaciones en el ámbito de la administración de justicia y los procesos democráticos.\n\nEl Anexo III, en su apartado 8, se refiere específicamente a sistemas de IA destinados a ser utilizados por una autoridad judicial o en su nombre para asistir a una autoridad judicial en la investigación y la interpretación de los hechos y del Derecho y en la aplicación de la ley a un conjunto concreto de hechos. Esta formulación, deliberadamente amplia, plantea cuestiones interpretativas significativas que abordaremos en la siguiente sección.\n\nEn tercer lugar, los sistemas de riesgo limitado quedan sujetos principalmente a obligaciones de transparencia. El ejemplo paradigmático son los sistemas de IA generativa, respecto de los cuales el Reglamento exige que el usuario sea informado de que está interactuando con contenido generado artificialmente o con un sistema automatizado. Finalmente, los sistemas de riesgo mínimo no están sujetos a obligaciones específicas derivadas del Reglamento, aunque pueden quedar afectados por otras normas sectoriales o por códigos de conducta voluntarios.\n\nEsta arquitectura basada en el riesgo, aparentemente clara en su diseño abstracto, plantea dificultades operativas en su aplicación concreta. La clasificación de un sistema específico no siempre resulta evidente, especialmente cuando se trata de herramientas de propósito general que pueden utilizarse en contextos diversos. La responsabilidad de la clasificación inicial recae sobre el proveedor del sistema, pero el usuario —en nuestro caso, el despacho, la administración o la institución— debe verificar la coherencia de dicha clasificación con el uso efectivo que pretende dar al sistema.\n\n## 3. La abogacía y la administración de justicia en el AI Act\n\nEl tratamiento de la administración de justicia en el Reglamento merece un análisis específico, dada su directa relevancia para el ejercicio profesional del Derecho. El Anexo III, apartado 8, somete al régimen de alto riesgo los sistemas de IA destinados a asistir a autoridades judiciales en la investigación e interpretación de hechos y Derecho. Esta previsión conecta con preocupaciones legítimas sobre el uso de sistemas automatizados en ámbitos donde están en juego derechos fundamentales como la tutela judicial efectiva, la presunción de inocencia o el derecho de defensa.\n\nSin embargo, la delimitación precisa del ámbito de aplicación de esta disposición no está exenta de dificultades. El texto se refiere a sistemas destinados a ser utilizados por una autoridad judicial o en su nombre. Esta formulación suscita interrogantes sobre el tratamiento de sistemas utilizados por abogados, procuradores u otros operadores jurídicos que, si bien no actúan en nombre de la autoridad judicial, participan en procesos que concluyen con decisiones judiciales.\n\nUna interpretación estricta del tenor literal conduciría a excluir del régimen de alto riesgo las herramientas de IA utilizadas por despachos de abogados en su labor de asistencia letrada, dado que el abogado no actúa por ni en nombre de la autoridad judicial. Sin embargo, esta interpretación podría resultar insatisfactoria desde una perspectiva teleológica: si la ratio de la norma es proteger a los ciudadanos frente a decisiones asistidas por IA en el ámbito judicial, parece coherente que dicha protección se extienda a todas las fases del proceso, incluyendo la asistencia letrada.\n\nLa cuestión admite matices adicionales. No es lo mismo un sistema de IA que asiste en la gestión documental de un expediente que uno que genera recomendaciones sobre la estrategia procesal a seguir o que evalúa la probabilidad de éxito de una pretensión. La intensidad del riesgo varía en función del grado de influencia que el sistema ejerce sobre decisiones con consecuencias jurídicas.\n\nAnte esta indefinición, la posición prudente para despachos e instituciones consiste en realizar una evaluación individualizada del uso previsto de cada sistema de IA, considerando no solo la clasificación proporcionada por el proveedor, sino el contexto específico de aplicación. En supuestos de duda razonable sobre la clasificación, la opción más conservadora es aplicar las obligaciones correspondientes a sistemas de alto riesgo, evitando así el riesgo de incumplimiento.\n\nEsta incertidumbre clasificatoria es una de las zonas grises más relevantes del Reglamento en su aplicación al sector jurídico. Es previsible que las guías interpretativas de la Comisión Europea y las posiciones de las autoridades nacionales competentes aporten clarificaciones en los próximos años, pero hasta entonces los operadores jurídicos deberán gestionar esta ambigüedad con criterio profesional.\n\n## 4. Obligaciones reales para despachos y organizaciones\n\nMás allá de las cuestiones clasificatorias, el Reglamento impone obligaciones concretas cuyo cumplimiento requiere acciones específicas por parte de los usuarios de sistemas de IA. Aunque el grueso del régimen obligacional recae sobre los proveedores, los usuarios —denominados deployers en la terminología del Reglamento— asumen responsabilidades propias que no pueden desconocerse.\n\n### 4.1. Supervisión humana\n\nEl artículo 14 del Reglamento exige que los sistemas de alto riesgo se diseñen y desarrollen de modo que permitan una supervisión humana efectiva durante su funcionamiento. Esta obligación, dirigida primariamente a los proveedores, tiene un correlato para los usuarios: garantizar que dicha supervisión se ejerce efectivamente.\n\nEn el contexto jurídico, esto implica que las decisiones asistidas por IA deben ser revisadas por un profesional cualificado antes de su formalización. La supervisión no puede ser meramente nominal o protocolaria; debe permitir la detección de errores, sesgos o resultados inadecuados. Esto exige, a su vez, que el profesional comprenda suficientemente el funcionamiento del sistema para identificar cuándo sus resultados son cuestionables.\n\nLa obligación de supervisión humana conecta con el principio de responsabilidad profesional. El uso de herramientas de IA no exime al abogado de su deber de diligencia ni transfiere al sistema la responsabilidad por el asesoramiento prestado. El profesional sigue siendo el garante último de la calidad y adecuación de su trabajo.\n\n### 4.2. Gobernanza de datos\n\nLos sistemas de alto riesgo están sujetos a requisitos específicos de calidad de los datos de entrenamiento, validación y prueba (artículo 10). Aunque esta obligación recae sobre el proveedor, el usuario debe ser consciente de los datos que introduce en el sistema durante su uso operativo, especialmente cuando se trata de datos personales o información sujeta a secreto profesional.\n\nEn despachos de abogados, la introducción de documentos de clientes en sistemas de IA generativa plantea cuestiones delicadas de confidencialidad y protección de datos. El usuario debe verificar las condiciones de tratamiento de datos del proveedor, las garantías de seguridad aplicables y, en su caso, la existencia de acuerdos de procesamiento de datos conformes con el RGPD.\n\n### 4.3. Trazabilidad y documentación\n\nEl Reglamento exige que los sistemas de alto riesgo dispongan de capacidades de registro automático de eventos (logging) que permitan trazar su funcionamiento (artículo 12). Para el usuario, esto implica la conveniencia de mantener registros propios sobre el uso del sistema: qué consultas se realizaron, qué resultados se obtuvieron, qué decisiones se adoptaron sobre la base de dichos resultados.\n\nEsta trazabilidad resulta especialmente relevante en caso de reclamaciones o procedimientos de responsabilidad. La capacidad de demostrar cómo se utilizó el sistema y qué controles se aplicaron puede ser determinante para la defensa frente a imputaciones de negligencia profesional.\n\n### 4.4. Transparencia frente al cliente\n\nEl Reglamento establece obligaciones de transparencia respecto de las personas afectadas por sistemas de IA. En el ámbito jurídico, esto plantea la cuestión de si el abogado debe informar a su cliente cuando utiliza herramientas de IA en la prestación del servicio.\n\nAunque el Reglamento no impone una obligación expresa de comunicación al cliente en todos los supuestos, los deberes deontológicos de lealtad y transparencia que rigen la relación abogado-cliente pueden exigir dicha comunicación, especialmente cuando el uso de IA tiene incidencia material en el asesoramiento o cuando el cliente ha manifestado preferencias al respecto. Las orientaciones de los colegios profesionales y las autoridades deontológicas serán relevantes para concretar el alcance de este deber.\n\n### 4.5. Relación con proveedores tecnológicos\n\nLos usuarios de sistemas de IA de alto riesgo deben verificar que los proveedores cumplen con las obligaciones que les impone el Reglamento. Esto tiene implicaciones contractuales directas: los contratos de suministro o licencia de software deben incluir cláusulas que garanticen el cumplimiento normativo del proveedor, establezcan mecanismos de verificación y regulen las consecuencias del incumplimiento.\n\nLa debida diligencia en la selección de proveedores forma parte de las obligaciones del usuario. No basta con adquirir una herramienta de IA y utilizarla sin más; es preciso verificar que el proveedor ha realizado las evaluaciones de conformidad exigidas, que dispone de la documentación técnica preceptiva y que ofrece las garantías necesarias para un uso conforme a Derecho.\n\n## 5. Relación entre AI Act y RGPD\n\nEl Reglamento de Inteligencia Artificial no opera de forma aislada, sino que se inserta en un ecosistema normativo más amplio del que forma parte destacada el Reglamento General de Protección de Datos (RGPD). La interacción entre ambos instrumentos plantea cuestiones de considerable complejidad que los operadores jurídicos deben tener presentes.\n\nEn primer lugar, el uso de sistemas de IA implica, en la mayoría de los casos, tratamiento de datos personales. La introducción de documentos, la generación de perfiles de riesgo, el análisis predictivo o la clasificación de expedientes son operaciones que típicamente involucran datos de personas físicas identificadas o identificables. Por tanto, el uso de IA en el contexto jurídico está sujeto simultáneamente al AI Act y al RGPD.\n\nLa exigencia de una base jurídica legítima para el tratamiento de datos personales se mantiene íntegramente. El usuario del sistema de IA debe verificar que dispone de base jurídica adecuada para los tratamientos que realiza, ya sea el consentimiento del interesado, la ejecución de un contrato, el cumplimiento de una obligación legal o el interés legítimo, según corresponda.\n\nEl principio de minimización de datos cobra especial relevancia en el contexto de la IA. Los sistemas de IA generativa, en particular, pueden procesar cantidades significativas de información que excedan lo estrictamente necesario para la finalidad perseguida. El usuario debe evaluar si la información introducida en el sistema es proporcionada y limitada a lo necesario.\n\nFinalmente, los derechos de los interesados (acceso, rectificación, supresión, oposición, no ser objeto de decisiones automatizadas) deben ser garantizados también en el entorno de la IA. El Reglamento de IA refuerza estos derechos con obligaciones específicas de transparencia y explicabilidad, pero no los sustituye. Los despachos deben estar preparados para responder a las solicitudes de ejercicio de derechos en relación con sistemas de IA.",
  "url": "https://derechoartificial.com/firma-scarpa/ai-act-practica-juridica"
}