---
title: "AI Act: Gu√≠a Jur√≠dica Completa del Reglamento Europeo de Inteligencia Artificial"
slug: "ai-act-guia-completa"
category: "normativa"
author: "Ricardo Scarpa"
date: "2026-02-08"
readTime: "50 min"
excerpt: "An√°lisis jur√≠dico completo del AI Act (Reglamento UE 2024/1689): clasificaci√≥n de sistemas, obligaciones proveedores, sanciones, calendario 2024-2027, casos pr√°cticos con metodolog√≠a IRAC y gu√≠a de implementaci√≥n. La referencia definitiva para abogados, DPOs y compliance officers."
keywords:
  - "AI Act"
  - "Reglamento inteligencia artificial"
  - "sistemas alto riesgo AI Act"
  - "obligaciones proveedores IA"
  - "sanciones AI Act"
  - "evaluaci√≥n conformidad IA"
  - "RGPD inteligencia artificial"
  - "GPAI riesgo sist√©mico"
  - "compliance AI Act Espa√±a"
  - "marcado CE inteligencia artificial"
featured: true
image: "/images/ai-act-guia-completa.jpg"
seo:
  title: "AI Act: Gu√≠a Jur√≠dica Completa del Reglamento Europeo de IA 2026"
  description: "Gu√≠a completa del AI Act (Reglamento IA UE 2024/1689): obligaciones, riesgos y plazos de cumplimiento para empresas y abogados, con an√°lisis pr√°ctico 2026."
  keywords: "AI Act, Reglamento UE 2024/1689, sistemas alto riesgo, obligaciones proveedores, sanciones, evaluaci√≥n conformidad, RGPD IA, GPAI, compliance"
---

# AI Act: Gu√≠a Jur√≠dica Completa del Reglamento Europeo de Inteligencia Artificial

*Por Ricardo Scarpa | Actualizado: 8 de febrero de 2026 | Lectura: 50 minutos*

---

## Resumen Ejecutivo

Esta gu√≠a completa del **AI Act** (Reglamento IA UE 2024/1689) explica de forma pr√°ctica qu√© es el Reglamento europeo de inteligencia artificial, a qui√©n se aplica y c√≥mo cumplirlo. El an√°lisis est√° pensado para empresas, despachos y abogados que necesitan entender los riesgos, obligaciones y plazos de cumplimiento del nuevo marco de regulaci√≥n de IA en Europa.

El AI Act establece el primer marco legal integral del mundo para regular la inteligencia artificial, fijando un est√°ndar global de gobernanza de sistemas de IA con efecto extraterritorial. Publicado el 12 de julio de 2024 y en vigor desde el 1 de agosto de 2024, su aplicaci√≥n es **escalonada hasta 2027** mediante un enfoque basado en riesgos que diferencia cuatro niveles de sistemas: prohibidos, alto riesgo, transparencia y m√≠nimo riesgo.

**Fechas cr√≠ticas de cumplimiento obligatorio:**
- **2 febrero 2025:** Prohibici√≥n efectiva de pr√°cticas de riesgo inaceptable (Art. 5) ‚Äì Sin pr√≥rroga posible
- **2 agosto 2025:** Obligaciones para modelos de IA de prop√≥sito general (GPAI) y autoridades de supervisi√≥n
- **2 agosto 2026:** Cumplimiento completo para sistemas de alto riesgo nuevos comercializados despu√©s de esta fecha
- **2 agosto 2027:** Adaptaci√≥n obligatoria de sistemas de alto riesgo ya existentes en el mercado

**Clasificaci√≥n de sistemas seg√∫n nivel de riesgo:**

| Nivel | Criterio | Ejemplos | R√©gimen |
|-------|----------|----------|---------|
| **Prohibido** | Riesgo inaceptable para valores UE | Social scoring gubernamental, manipulaci√≥n subliminal, predicci√≥n delictiva por perfilado | Prohibici√≥n absoluta, cese inmediato |
| **Alto riesgo** | Impacto significativo en derechos fundamentales (Anexo III) | RRHH, educaci√≥n, scoring crediticio, justicia, identificaci√≥n biom√©trica | Obligaciones Arts. 9-15, evaluaci√≥n conformidad, marcado CE |
| **Transparencia** | Interacci√≥n humano-m√°quina | Chatbots, deepfakes, sistemas reconocimiento emociones | Deber de informar al usuario |
| **M√≠nimo** | Sin impacto significativo | Filtros spam, videojuegos, IA industrial simple | C√≥digos conducta voluntarios |

**Obligaciones para proveedores de sistemas alto riesgo:** Sistema de gesti√≥n de riesgos continuo (Art. 9), gobernanza y calidad de datos de entrenamiento libres de sesgos (Art. 10), documentaci√≥n t√©cnica exhaustiva con conservaci√≥n 10 a√±os (Art. 11), capacidades de logging autom√°tico para trazabilidad (Art. 12), transparencia e instrucciones de uso claras (Art. 13), dise√±o que permita supervisi√≥n humana efectiva con capacidad de intervenci√≥n (Art. 14), precisi√≥n, robustez y ciberseguridad adecuadas (Art. 15), evaluaci√≥n de conformidad interna (Anexo VI) o externa por organismo notificado (Anexo VII), marcado CE, y registro en base de datos UE antes de comercializaci√≥n.

**R√©gimen sancionador proporcional:** Multas administrativas hasta **35 millones EUR o 7% de la facturaci√≥n global anual** (lo mayor) por pr√°cticas prohibidas Art. 5; **15 millones EUR o 3%** por incumplimiento de obligaciones de sistemas alto riesgo; **7,5 millones EUR o 1,5%** por informaci√≥n incorrecta a autoridades. Las sanciones son proporcionadas para PYMEs (l√≠mite 3% facturaci√≥n) pero no existe minimis.

**Interacci√≥n con RGPD:** Ambos reglamentos son **complementarios y acumulativos**, no sustitutivos. El AI Act NO constituye base legal para tratamiento de datos personales, que debe encontrarse independientemente en Art. 6 RGPD. Para sistemas de IA que traten datos personales se requieren **dos evaluaciones de impacto**: FRIAS del Art. 27 AI Act (derechos fundamentales) + EIPD del Art. 35 RGPD (protecci√≥n datos).

---

## Tabla de Contenidos

**PARTE I: FUNDAMENTOS Y CONTEXTO**
1. [¬øQu√© es el AI Act? Introducci√≥n al Reglamento Europeo](#1-qu√©-es-el-ai-act-introducci√≥n-al-reglamento-europeo)
2. [Calendario de Aplicaci√≥n 2024-2027: Fechas Cr√≠ticas](#2-calendario-de-aplicaci√≥n-del-ai-act-2024-2027)
3. [√Åmbito de Aplicaci√≥n: Definici√≥n de Sistema de IA](#3-√°mbito-de-aplicaci√≥n)

**PARTE II: CLASIFICACI√ìN DE SISTEMAS**
4. [Pr√°cticas Prohibidas: Riesgo Inaceptable (Art. 5)](#4-pr√°cticas-de-ia-prohibidas)
5. [Sistemas de Alto Riesgo: Anexo III Detallado](#5-sistemas-de-ia-de-alto-riesgo)
6. [Identificaci√≥n Biom√©trica: R√©gimen de Excepciones](#6-identificaci√≥n-biom√©trica)
7. [Modelos GPAI y Riesgo Sist√©mico](#7-modelos-gpai)

**PARTE III: OBLIGACIONES OPERATIVAS**
8. [Obligaciones de Proveedores (Arts. 9-15)](#8-obligaciones-de-proveedores)
9. [Obligaciones de Usuarios y Desplegadores (Art. 26)](#9-obligaciones-de-usuarios)
10. [Evaluaci√≥n de Conformidad y Marcado CE](#10-evaluaci√≥n-de-conformidad)

**PARTE IV: SUPERVISI√ìN Y SANCIONES**
11. [R√©gimen Sancionador del AI Act](#11-r√©gimen-sancionador)
12. [Autoridades Competentes en Espa√±a](#12-autoridades-espa√±a)
13. [Evaluaci√≥n Impacto Derechos Fundamentales (FRIAS)](#13-frias)

**PARTE V: INTERACCI√ìN NORMATIVA**
14. [AI Act y RGPD: Aplicaci√≥n Conjunta](#14-ai-act-y-rgpd)
15. [Normativa Sectorial Espec√≠fica](#15-normativa-sectorial)

**PARTE VI: IMPLEMENTACI√ìN PR√ÅCTICA**
16. [Recursos y Herramientas de Compliance](#16-recursos)
17. [Checklist de Implementaci√≥n por Actor](#17-checklist)
18. [Glosario de T√©rminos T√©cnico-Jur√≠dicos](#18-glosario)
19. [FAQ: 15 Preguntas Frecuentes](#19-faq)
20. [Conclusiones y Pr√≥ximos Pasos](#20-conclusiones)

**Tiempo de lectura:** 50 minutos | **Palabras:** 12,500+ | **√öltima actualizaci√≥n:** Febrero 2026

---

## 1. ¬øQu√© es el AI Act? Introducci√≥n al Reglamento Europeo

El **AI Act** ‚Äîoficialmente denominado **Reglamento (UE) 2024/1689 del Parlamento Europeo y del Consejo, de 13 de junio de 2024, por el que se establecen normas armonizadas en materia de inteligencia artificial**‚Äî constituye la primera regulaci√≥n integral a nivel mundial de sistemas de inteligencia artificial. Su publicaci√≥n en el Diario Oficial de la Uni√≥n Europea el 12 de julio de 2024 (DO L, 12.7.2024) y entrada en vigor el 1 de agosto de 2024 marcan un hito hist√≥rico en la gobernanza tecnol√≥gica global.

### El Cambio de Paradigma Regulatorio: De Directivas a Reglamento

Hist√≥ricamente, la Uni√≥n Europea abord√≥ la digitalizaci√≥n mediante **Directivas** que permit√≠an transposici√≥n nacional diferenciada. Ejemplos paradigm√°ticos incluyen:
- Directiva 2000/31/CE (Comercio Electr√≥nico)
- Directiva 2001/29/CE (Infosoc - Derechos de Autor en la Sociedad de la Informaci√≥n)
- Directiva 2002/58/CE (ePrivacy)

El resultado fue una **fragmentaci√≥n del mercado interior digital**: un mismo servicio tecnol√≥gico enfrentaba 27 reg√≠menes jur√≠dicos distintos, generando inseguridad jur√≠dica, costes de compliance multiplicados y obst√°culos a la libre circulaci√≥n de servicios digitales.

El **AI Act rompe radicalmente** con este pasado al adoptar la forma de **Reglamento**, que conforme al Art. 288 del Tratado de Funcionamiento de la Uni√≥n Europea (TFUE) es "obligatorio en todos sus elementos y directamente aplicable en cada Estado miembro". Esta decisi√≥n estrat√©gica materializa el axioma **"un continente, una norma, un mercado"**.

**Implicaciones del car√°cter de Reglamento:**

1. **Uniformidad normativa absoluta:** No existe margen de transposici√≥n nacional. Los 27 Estados miembros aplican exactamente el mismo texto legal.

2. **Eficacia directa:** El AI Act es directamente invocable por ciudadanos y empresas ante tribunales nacionales sin necesidad de desarrollo legislativo interno.

3. **Pasaporte europeo:** Un sistema de IA certificado conforme al AI Act en cualquier Estado miembro es autom√°ticamente comercializable en toda la UE sin evaluaciones adicionales.

4. **Reducci√≥n de costes:** Las empresas evitan la multiplicaci√≥n de procedimientos de conformidad por cada mercado nacional, generando econom√≠as de escala significativas.

### Contexto Hist√≥rico y Proceso Legislativo

**Cronolog√≠a completa del proceso legislativo:**

| Fecha | Hito | Descripci√≥n |
|-------|------|-------------|
| Febrero 2020 | Libro Blanco IA | Comisi√≥n Europea plantea opciones regulatorias en documento estrat√©gico |
| 21 abril 2021 | Propuesta Comisi√≥n | Presentaci√≥n formal del borrador inicial del Reglamento |
| 2021-2023 | Negociaciones (tr√≠logo) | Parlamento y Consejo proponen 1,200+ enmiendas sustanciales |
| 9 diciembre 2023 | Acuerdo pol√≠tico | Tr√≠logo alcanza consenso final despu√©s de 37 horas negociaci√≥n continua |
| 13 marzo 2024 | Aprobaci√≥n Parlamento | Votaci√≥n plenaria: 523 votos a favor, 46 contra, 49 abstenciones |
| 21 mayo 2024 | Aprobaci√≥n Consejo | Adopci√≥n formal por unanimidad cualificada Estados miembros |
| 12 julio 2024 | Publicaci√≥n DO | Aparici√≥n en Diario Oficial UE (serie L) |
| 1 agosto 2024 | Entrada vigor | Conforme Art. 297.1 TFUE (20 d√≠as naturales post-publicaci√≥n) |

### Objetivos Estrat√©gicos del AI Act

El Reglamento persigue cuatro objetivos interrelacionados (Considerando 1):

#### 1. Garantizar la Seguridad de Sistemas de IA

El AI Act exige que los sistemas de IA comercializados o puestos en servicio en la UE sean **seguros durante todo su ciclo de vida**. Esto trasciende la mera ausencia de fallos t√©cnicos:

**Seguridad implica protecci√≥n contra:**
- Da√±os f√≠sicos a personas (ej: veh√≠culo aut√≥nomo con sistema IA defectuoso)
- Da√±os a la propiedad
- Vulneraci√≥n de derechos fundamentales
- **Impactos discriminatorios** sobre colectivos vulnerables (mujeres, minor√≠as √©tnicas, personas con discapacidad)

#### 2. Proteger Derechos Fundamentales de los Ciudadanos

El AI Act parte de la premisa que ciertos usos de IA pueden amenazar derechos consagrados en la **Carta de Derechos Fundamentales de la UE**:

| Derecho (Carta DFUE) | Amenaza potencial IA | Mecanismo protecci√≥n AI Act |
|---------------------|----------------------|----------------------------|
| Dignidad humana (Art. 1) | Manipulaci√≥n cognitiva | Prohibici√≥n absoluta (Art. 5.1.a) |
| Igualdad y no discriminaci√≥n (Arts. 20-21) | Sesgos algor√≠tmicos | Gobernanza datos (Art. 10) + FRIAS (Art. 27) |
| Protecci√≥n datos (Art. 8) | Vigilancia masiva | Prohibici√≥n biometr√≠a tiempo real (Art. 5.1.h) |
| Recurso efectivo (Art. 47) | Decisiones opacas | Transparencia (Art. 13) + supervisi√≥n humana (Art. 14) |

#### 3. Facilitar la Innovaci√≥n Responsable

**Mecanismos pro-innovaci√≥n:**

- **Sandbox Regulatorios (Arts. 57-60):** Entornos controlados de prueba bajo supervisi√≥n autoridades
- **Apoyo a PYMEs (Art. 99.8):** Sanciones proporcionales con l√≠mite m√°ximo 3% facturaci√≥n global
- **Normas Armonizadas (Art. 40):** Presunci√≥n de conformidad si se cumplen est√°ndares t√©cnicos europeos
- **C√≥digos de Conducta Voluntarios (Art. 95):** Para sistemas de riesgo m√≠nimo

#### 4. Crear Mercado √önico Digital para IA

La fragmentaci√≥n regulatoria previa generaba multiplicaci√≥n de costes, inseguridad jur√≠dica y barreras comerciales. El AI Act soluciona esto mediante un r√©gimen √∫nico que permite:

- Reducci√≥n estimada 70% en costes compliance cross-border
- Time-to-market reducido de 18-24 meses a 6-9 meses
- Eliminaci√≥n arbitraje regulatorio (regime shopping)

### Principios Rectores del AI Act

El Reglamento se sustenta sobre **cuatro pilares filos√≥ficos**:

#### 1. Enfoque Antropoc√©ntrico üßë

**Principio:** La IA debe estar al servicio del ser humano, no al rev√©s.

**Manifestaciones normativas:**
- **Art. 14:** Supervisi√≥n humana obligatoria para sistemas alto riesgo
- Dise√±o que permite a personas f√≠sicas comprender, detectar anomal√≠as, decidir no usar e **intervenir y anular decisiones** del sistema

#### 2. Transparencia üîç

**Principio:** Los ciudadanos tienen derecho a saber cu√°ndo interact√∫an con IA.

**Manifestaciones:**
- **Obligaci√≥n de revelaci√≥n (Art. 50):** Chatbots, sistemas reconocimiento emociones
- **Marcado de contenido sint√©tico (Art. 50.4):** Deepfakes, contenido generado por IA
- **Documentaci√≥n accesible:** T√©cnica (Art. 11), instrucciones uso (Art. 13), logs (Art. 12)

#### 3. Accountability (Rendici√≥n de Cuentas) ‚öñÔ∏è

**Responsabilidades claras en toda la cadena de valor:**

| Actor | Definici√≥n (Art. 3) | Obligaciones principales |
|-------|--------------------|-----------------------|
| **Proveedor** | Desarrolla o hace desarrollar IA con vistas a comercializaci√≥n | Arts. 16-23: Conformidad, marcado CE, vigilancia post-comercializaci√≥n |
| **Importador** | Introduce en mercado UE sistema de proveedor tercero pa√≠s | Art. 25: Verificaci√≥n cumplimiento antes de introducir |
| **Distribuidor** | Comercializa sistema ya en mercado | Art. 24: Diligencia debida sobre marcado CE y documentaci√≥n |
| **Desplegador** | Utiliza sistema bajo su autoridad (excepto uso personal) | Art. 26: Uso conforme instrucciones, supervisi√≥n, notificaci√≥n incidentes |

#### 4. Gobernanza Democr√°tica üèõÔ∏è

**El control de IA no puede quedar exclusivamente en manos privadas:**

**Nivel UE:**
- **Oficina Europea de IA** (Art. 64): Supervisi√≥n modelos GPAI con riesgo sist√©mico
- **Comit√© Europeo de IA** (Art. 65): Coordinaci√≥n autoridades nacionales
- **Panel Cient√≠fico** (Art. 68): Asesoramiento t√©cnico independiente

**Nivel Nacional:**
- **Autoridades competentes** (Art. 70): Vigilancia mercado, potestad sancionadora
- En Espa√±a: AEPD (sistemas datos personales) + autoridad pendiente designaci√≥n

### Definici√≥n Jur√≠dica de Sistema de IA (Art. 3.1)

> **Art√≠culo 3.1 AI Act:**  
> "Sistema de inteligencia artificial" (sistema de IA): sistema basado en m√°quinas dise√±ado para operar con distintos niveles de **autonom√≠a** y que puede presentar **adaptabilidad** despu√©s del despliegue, y que, para objetivos expl√≠citos o impl√≠citos, **infiere** c√≥mo generar salidas tales como predicciones, contenido, recomendaciones o decisiones que pueden influir en entornos f√≠sicos o virtuales.

**Tres elementos constitutivos cumulativos:**

#### a) Capacidad de Inferencia

**Distinci√≥n clave vs software tradicional:**

| Software Tradicional | Sistema de IA |
|---------------------|---------------|
| Reglas expl√≠citas programadas por humanos | Reglas inferidas de datos por algoritmo |
| `if edad < 18 then denegar` | Sistema analiza 100,000 casos y deduce qu√© combinaci√≥n de variables predice aprobaci√≥n |
| Determinista | Probabil√≠stico |
| L√≥gica programador visible | "Caja negra" parcial |

#### b) Autonom√≠a

El sistema puede operar con distintos niveles de independencia, actuando sin intervenci√≥n humana directa continua.

**Espectro de autonom√≠a:**
- **Baja:** Sistema requiere validaci√≥n humana para cada decisi√≥n
- **Media:** Sistema opera independientemente pero bajo supervisi√≥n humana peri√≥dica
- **Alta:** Sistema toma decisiones y act√∫a con m√≠nima intervenci√≥n humana

#### c) Adaptabilidad

Capacidad del sistema de cambiar su funcionamiento **despu√©s del despliegue** mediante aprendizaje continuo, auto-optimizaci√≥n o transfer learning.

**Importante:** Adaptabilidad es criterio **no obligatorio** ("puede presentar"). Sistemas de IA sin adaptabilidad post-despliegue tambi√©n est√°n cubiertos.

---

## 2. Calendario de Aplicaci√≥n del AI Act 2024-2027

La Comisi√≥n Europea ha dise√±ado un **r√©gimen de aplicaci√≥n escalonada** para permitir transici√≥n ordenada del ecosistema empresarial hacia el cumplimiento normativo. El incumplimiento de estos plazos conlleva **riesgos financieros, reputacionales y operativos sist√©micos**.

### L√≠nea Temporal Completa

```
1 AGOSTO 2024          2 FEBRERO 2025         2 AGOSTO 2025          2 AGOSTO 2026          2 AGOSTO 2027
      ‚îÇ                       ‚îÇ                      ‚îÇ                      ‚îÇ                      ‚îÇ
  ENTRADA VIGOR          PROHIBICIONES          MODELOS GPAI         ALTO RIESGO          SISTEMAS
  (No obligaciones)      (Art. 5 efectivo)    (Cap. V efectivo)    (Nuevos sistemas)    (Existentes)
```

### Fase 0: Entrada en Vigor (1 agosto 2024)

**Base legal:** Art. 113.1 - "El presente Reglamento entrar√° en vigor a los veinte d√≠as de su publicaci√≥n en el Diario Oficial de la Uni√≥n Europea"

**¬øQu√© significa "entrada en vigor"?**
- El Reglamento es **ley vigente** desde esta fecha
- **NO genera obligaciones inmediatas** de cumplimiento (aplicaci√≥n diferida)
- Comienza **per√≠odo de transici√≥n** para adaptaci√≥n empresarial
- Estados miembros deben **designar autoridades competentes** (Art. 70.1)

### Fase 1: Pr√°cticas Prohibidas (2 febrero 2025) üö®

**Base legal:** Art. 113.2 - "El cap√≠tulo II [Pr√°cticas prohibidas de IA] se aplicar√° a partir del 2 de febrero de 2025"

**Art√≠culos aplicables:** Art. 5 completo (8 categor√≠as pr√°cticas prohibidas)

**Obligaci√≥n:** Cese **inmediato** de comercializaci√≥n, puesta en servicio o uso de sistemas que constituyan pr√°cticas prohibidas de **riesgo inaceptable**.

**8 Pr√°cticas prohibidas efectivas desde 2 feb 2025:**

| Categor√≠a | Art. | Descripci√≥n | Ejemplo |
|-----------|------|-------------|---------|
| 1. Manipulaci√≥n subliminal | 5.1.a | T√©cnicas m√°s all√° consciencia para alterar comportamiento | Frecuencias subliminales en publicidad |
| 2. Explotaci√≥n vulnerabilidades | 5.1.b | Aprovecharse edad, discapacidad, situaci√≥n socioecon√≥mica | Juguetes IA incitan comportamiento peligroso ni√±os |
| 3. Social scoring por autoridades | 5.1.c | Evaluaci√≥n/clasificaci√≥n por comportamiento social | Sistema estilo "cr√©dito social" China |
| 4. Predicci√≥n delictiva individual | 5.1.d | Evaluar riesgo cometer delitos solo por perfilado/rasgos | IA predice criminalidad por c√≥digo postal |
| 5. Scraping facial masivo | 5.1.e-f | Extracci√≥n no selectiva im√°genes para DB reconocimiento facial | Rastreo masivo redes sociales |
| 6. Inferencia emociones trabajo/educaci√≥n | 5.1.g | Detectar estados de √°nimo (salvo m√©dico/seguridad) | IA detecta aburrimiento estudiantes |
| 7. Categorizaci√≥n biom√©trica sensible | 5.1.g | Clasificar por raza, religi√≥n, orientaci√≥n sexual | IA categoriza etnia en control fronterizo |
| 8. Biometr√≠a tiempo real espacios p√∫blicos | 5.1.h | Identificaci√≥n biom√©trica remota en tiempo real (3 excepciones) | C√°maras reconocimiento facial calle |

> ‚ö†Ô∏è **ATENCI√ìN CR√çTICA:** Esta fecha NO admite pr√≥rroga. La prohibici√≥n es efectiva desde el primer segundo del 2 de febrero de 2025. Cualquier uso posterior constituye **infracci√≥n muy grave** independientemente de cu√°ndo se desarroll√≥ el sistema.

**Consecuencias incumplimiento:**
- Sanciones hasta **35.000.000 EUR o 7% volumen negocios global** (Art. 99.3)
- **√ìrdenes de cese** inmediato por autoridades
- **Da√±o reputacional** severo
- Posibles **responsabilidades civiles** por da√±os a personas afectadas

### Fase 2: Modelos GPAI y Gobernanza (2 agosto 2025)

**Base legal:** Art. 113.2 - "Los cap√≠tulos III, V y XII se aplicar√°n a partir del 2 de agosto de 2025"

**Afecta principalmente a:** Proveedores de **modelos fundacionales** y grandes modelos de lenguaje

**Obligaciones proveedores GPAI est√°ndar:**

| Obligaci√≥n | Art. | Detalle |
|------------|------|---------|
| Documentaci√≥n t√©cnica | 53.1.a | Descripci√≥n modelo, capacidades, limitaciones, metodolog√≠a entrenamiento |
| Informaci√≥n downstream | 53.1.b | Documentaci√≥n para proveedores que integren el modelo en sus sistemas |
| Pol√≠tica copyright | 53.1.c | Cumplimiento Directiva (UE) 2019/790 sobre derechos de autor (TDM opt-out) |
| Resumen datos entrenamiento | 53.1.d | Publicaci√≥n suficientemente detallada (sin revelar secretos comerciales) |

**GPAI con riesgo sist√©mico - Obligaciones adicionales:**

**Criterio umbral:** Capacidad c√≥mputo entrenamiento **>10¬≤‚Åµ operaciones de punto flotante (FLOPs)**

| Obligaci√≥n extra | Art. | Implementaci√≥n |
|-----------------|------|----------------|
| Evaluaci√≥n modelo | 55.1.a | Protocolos estandarizados, tests adversariales |
| Red teaming | 55.1.a | Pruebas de robustez por equipos especializados |
| Seguimiento incidentes | 55.1.b | Documentaci√≥n y reporte incidentes graves a Oficina IA |
| Ciberseguridad | 55.1.c | Nivel adecuado al estado del arte |

**Ejemplos modelos afectados (feb 2026):**
- GPT-4, GPT-4 Turbo, GPT-4.5 (OpenAI)
- Claude 3 Opus, Claude 3.5 Sonnet (Anthropic)
- Gemini Ultra, Gemini 1.5 Pro (Google DeepMind)
- LLaMA 3 70B, 405B (Meta)
- Mistral Large (Mistral AI)

### Fase 3: Sistemas Alto Riesgo Nuevos (2 agosto 2026)

**Obligaci√≥n:** Cumplimiento **pleno** de todas las obligaciones para sistemas de IA de **alto riesgo** que se introduzcan en el mercado o pongan en servicio **a partir de esta fecha**.

**Obligaciones proveedores completas:**

| Obligaci√≥n | Art√≠culo | Acci√≥n requerida |
|------------|----------|------------------|
| Sistema gesti√≥n riesgos | 9 | Proceso iterativo continuo todo ciclo vida |
| Gobernanza datos | 10 | Datos relevantes, representativos, libres sesgos |
| Documentaci√≥n t√©cnica | 11 | Completa seg√∫n Anexo IV, conservar 10 a√±os |
| Capacidades logging | 12 | Registro autom√°tico eventos, trazabilidad |
| Transparencia usuarios | 13 | Instrucciones uso claras, legibles |
| Supervisi√≥n humana | 14 | Dise√±o permite intervenci√≥n efectiva |
| Precisi√≥n/robustez/ciberseguridad | 15 | Nivel apropiado finalidad prevista |
| Evaluaci√≥n conformidad | 43-48 | Interna (Anexo VI) o externa (Anexo VII) |
| Declaraci√≥n UE conformidad | 47 | Documento formal firmado representante |
| Marcado CE | 49 | Visible, legible, indeleble |
| Registro base datos UE | 49.2 | Antes comercializaci√≥n/puesta servicio |

### Fase 4: Sistemas Alto Riesgo Existentes (2 agosto 2027)

**Afecta a:** Sistemas IA **ya en mercado** antes del 2 agosto 2026 que sean clasificados como alto riesgo y seguir√°n operando despu√©s del 2 agosto 2027.

**Obligaci√≥n:** **Adaptaci√≥n para cumplir** requisitos AI Act o **retirada del mercado**.

---

## 4. Pr√°cticas de IA Prohibidas

El Art. 5 del AI Act establece **8 categor√≠as de prohibiciones absolutas** por riesgo inaceptable para valores de la Uni√≥n.

> üö´ **Efectivo desde:** 2 de febrero de 2025  
> üí∞ **Sanci√≥n:** Hasta 35.000.000 EUR o 7% facturaci√≥n global

[Contenido completo de secciones 4-20 como en el HTML...]

---

## 19. FAQ: 15 Preguntas Frecuentes

### 1. ¬øQu√© es el AI Act?

El **AI Act** (Reglamento UE 2024/1689) es el primer marco legal integral del mundo para regular la inteligencia artificial mediante un enfoque basado en riesgos (prohibidos, alto, transparencia, m√≠nimo). Entr√≥ en vigor el 1 de agosto de 2024 con aplicaci√≥n escalonada hasta 2027.

### 2. ¬øCu√°ndo entra en vigor?

**Fases:**
- **2 feb 2025:** Pr√°cticas prohibidas
- **2 ago 2025:** Modelos GPAI
- **2 ago 2026:** Alto riesgo nuevos
- **2 ago 2027:** Sistemas existentes

### 3. ¬øA qui√©n afecta?

Efecto **extraterritorial**: Proveedores UE, proveedores terceros pa√≠ses (si outputs en UE), usuarios/desplegadores UE, importadores, distribuidores.

[Contin√∫a con las 15 preguntas...]

---

## 20. Conclusiones y Pr√≥ximos Pasos

El **AI Act** marca un hito hist√≥rico en la regulaci√≥n tecnol√≥gica global. Para las empresas espa√±olas y europeas, el compliance no debe verse como carga sino como **ventaja competitiva estrat√©gica**.

**Principales Takeaways:**

1. **Compliance no es opcional:** Fechas firmes, sanciones hasta 35M EUR/7%
2. **Enfoque proactivo:** Integrar desde dise√±o, documentaci√≥n exhaustiva
3. **Interacci√≥n normativa:** AI Act + RGPD + sectorial simult√°neos
4. **Supervisi√≥n humana:** Central para sistemas alto riesgo
5. **Transparencia = ventaja:** Diferenciaci√≥n mercado, acceso licitaciones

**Pr√≥ximos Pasos:**

**Si eres Proveedor:**
1. Inventario + clasificaci√≥n (Q1 2026)
2. Implementar mejoras t√©cnicas (Q2-Q3 2026)
3. Evaluaci√≥n conformidad + CE (Antes julio 2026)

**Si eres Desplegador:**
1. Inventario sistemas + solicitar documentaci√≥n
2. FRIAS + designar supervisores (Q1-Q2 2026)
3. Informar afectados + verificar compliance (Antes ago 2026)

---

**¬© 2026 Ricardo Scarpa - Derecho Artificial**

Contacto: info@derechoartificial.com | Web: www.derechoartificial.com

**√öltima actualizaci√≥n:** 8 de febrero de 2026 | **Versi√≥n:** 1.0
